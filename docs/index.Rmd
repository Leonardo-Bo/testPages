---
title: "Esempio di applicazione di R Markdown (R Notebook)"
output:
  html_notebook: default
  pdf_document: default
---

Come esempio di funzionamento di `Rmarkdown` proviamo a riscrivere un paio di esempi presenti nelle prime 28 pagine delle dispense. Questo vuol dire che le formule e i contenuti avranno meno spazio, ma ci si può comunque fare un'idea delle potenzialità di questo strumento.

# Esempio 1

Il primo esempio nella sua versione originale è:

```{r}
# reproducibility
set.seed(1)

size_pop = 1000
size_samp <- 100

# defining the population randomly
pop <- runif(size_pop, min = 0, max = 1)

# Simple random sampling
samp_cont <- sample(length(pop),size_samp)
samp <- pop[samp_cont]
plot(density(pop), xlim=c(0,1), ylim=c(0,2), col="blue")
par(new=T)
plot(density(samp), xlim=c(0,1), ylim=c(0,2), col="red")

# Systematic sampling
samp_cont <- seq(from = 1, to = size_pop, by = 10)
samp <- pop[samp_cont]
plot(density(pop), xlim=c(0,1), ylim=c(0,2), col="blue")
par(new=T)
plot(density(samp), xlim=c(0,1), ylim=c(0,2), col="red")
```

Come possiamo vedere va leggermente ritoccato modificando il titolo e il label dell'asse $x$. Aggiungo un altro paio di commenti, pur consapevole che si tratta di un esempio *semplice*: 

1. usare `par` può rivelarsi *pericoloso*, perché se ce ne sono diversi nel testo e ci si dimentica come si è settato l'output, può essere difficile andarlo a ritrovare;

2. `plot` consente di fare grafici con una certa rapidità, ma la qualità di default non è elevata. Un altro problema nell'usare `par` è rappresentato dalle trame *raddoppiate* che rendono il nero ancor più nero.

Entrambi i problemi possono essere risolti con sia con `plot` che con `ggplot2`. Certo, in entrambi i casi c'è un prezzo da pagare: 

- con `plot` si devono usare una serie di *trucchi* grafici che possono complicarsi molto anche per plot non estremamente difficili; 

- con `ggplot2` si devono organizzare i dati prima di rappresentarli. Tuttavia quello che all'inizio può sembrare difficile, porta a quello che forse è il punto più importante nella programmazione scientifica: dimestichezza nel maneggiare e ordinare dati. 

Vediamo come rappresentare i dati precedenti con `ggplot2`:

```{r}
library(ggplot2)

# reproducibility
set.seed(1)

size_pop = 1000
size_samp <- 100

# defining the population randomly
pop <- runif(size_pop, min = 0, max = 1)

# Simple random sampling
samp_cont <- sample(length(pop),size_samp)
samp <- pop[samp_cont]

df_exapmle1 <- data.frame(
  values = c(pop, samp), 
  type = c(rep("population", length(pop)), rep("sample", length(samp)))
)

ggplot(df_exapmle1) + 
  geom_density(aes(values, color = type))
```

# Esempio 7
Ho scelto questo esempio perché si presta bene al doppio approccio `R-base` - `tidyverse`. Ovviamente il codice fa ciò che deve in entrambi i casi e questo è l'importante. 

```{r}
library(bio3d)
pdb_aus <- read.pdb("5T0O")
df_coord <- pdb_aus$atom
df_coord <-
df_coord[!df_coord$resid%in%unique(df_coord$resid)[length(unique(df_coord$resid))],]

# setting parameters
cutoff <- 12
df_coord$NewResName <- paste(df_coord$resno, df_coord$resid, df_coord$chain, sep="_")

# centroid calculation
newResName <- unique(df_coord$NewResName)
df_centroidCoord <- data.frame()
for(i in 1:length(newResName)){
res_aus <- newResName[i]
df_coord_aus <- df_coord[df_coord$NewResName %in% res_aus, ]
coord_aus <- apply(df_coord_aus[,c("x","y","z")],2,mean)
df_centroidCoord <- as.matrix(rbind(df_centroidCoord,coord_aus))
}

df_centroidCoord <- apply(df_centroidCoord,2,as.numeric)
df_centroidCoord <- as.data.frame(df_centroidCoord)
rownames(df_centroidCoord) <- newResName
# contacts matrix definition
DistMat <- as.matrix(dist(df_centroidCoord))
vet_aa_inter <- c()
for(i in 1:nrow(DistMat)){
rownames_aus <- rownames(DistMat)[i]
aa_aus <- unlist(strsplit(rownames_aus,"_"))[2]
aa_int_aus <- names(DistMat[i,][DistMat[i,] <= cutoff & DistMat[i,]!=0])
aa_int_aus_aus <-as.character(do.call(rbind,strsplit(aa_int_aus,"_"))[,2])
vet_aa_inter <- c(vet_aa_inter, paste(aa_aus,aa_int_aus_aus, sep="-"))
}
summary_conct <- table(vet_aa_inter)
summary_conct_prob <- summary_conct/sum(summary_conct)

head(summary_conct)
head(summary_conct_prob)
```

L'esempio continua ma mi fermo qui.  
Proviamo a riscrivere tutto utilizzando le potenzialità dei pacchetti dell'universo `tidyverse`:

```{r}
pdb_aus <- read.pdb("5T0O")

df_aa_contact <- pdb_aus$atom %>% 
  # filter only aminoacids
  filter(resid %in% aa.table$aa3) %>% 
  
  # add NewResName column
  mutate(NewResName = paste(resno, resid, chain, sep = "_")) %>% 
  
  # group by NewResName
  group_by(NewResName) %>% 
  
  # for each group defined below apply mean function on x y and z column: define centroids
  summarise(cx = mean(x), cy = mean(y), cz = mean(z)) %>% 
  
  # create all pair-wise of centroids
  full_join(x = ., y = ., by = character(), suffix = c("", "_2")) %>%
  
  # remove pair-wise same centroids
  filter(NewResName != NewResName_2) %>%
  
  # add new column distance. Now we have NewResName, cx, cy, cz, NewResName_2, cx_2, cy_2, cz_2, distance
  mutate(distance = sqrt((cx - cx_2)^2 + (cy - cy_2)^2 + (cz - cz_2)^2)) %>%
  
  # get only NewResName, NewResName_2, distance columns
  select(NewResName, NewResName_2, distance) %>%
  
  # get new dataframe wit pair_aa column (es ALA-ALA, ALA-ARG) and contact column based on cutoff
  summarise(
    pair_aa = paste(substr(NewResName, nchar(NewResName) - 4, nchar(NewResName) - 2), 
                    substr(NewResName_2, nchar(NewResName_2) - 4, nchar(NewResName_2) - 2), 
                    sep = "-"), 
    contact = if_else(distance < cutoff, 1, 0)
  ) %>%
  
  # group by pair_aa
  group_by(pair_aa) %>%
  
  # get new dataframe with pair_aa and contacts count for each pair
  summarise(count = sum(contact)) %>%
  
  # add frequence
  mutate(freq = count/sum(count))

head(df_aa_contact)
```
`mutate`: aggiunge colonne al dataframe in esame
`summarise`: riassume i dati del dataframe in esame in un nuovo dataframe
`filter`: filtra le righe del dataframe in base a condizioni
`selec`: seleziona colonne del dataframe

È interessante come con questo approccio il flusso sia sempre da sinistra a destra. Partiamo da un dataframe `X`, lo diamo in pasto a un'operazione tramite la pipe `%>%` e otteniamo un nuovo dataframe da dare in pasto a un'altra operazione. 

Di tutto il codice precedente a mio parere due righe sono abbastanza *oscure*: 
- `full_join`, che fa una magia
- la definizione di `pair_aa`. Ma in tutti i linguaggi di programmazione che conosco, non ce n'è uno dove le stringhe non siano un problema. In questo caso vogliamo passare da `"1_ALA_A"` della colonna `NewResName` e `"2_ARG_B"` della colonna `NewResName_2` a `ALA-ARG` della colonna `pair_aa`. 

Notiamo che i due approcci restituiscono gli stessi risultati, ma organizzati diversamente: 

- due vettori nel primo caso
- un dataframe nel secondo

Concludiamo con un banchmark

```{r, echo=FALSE}
app1 <- function() {
  df_coord <- pdb_aus$atom
  df_coord <-
  df_coord[!df_coord$resid%in%unique(df_coord$resid)[length(unique(df_coord$resid))],]
  
  # setting parameters
  cutoff <- 12
  df_coord$NewResName <- paste(df_coord$resno, df_coord$resid, df_coord$chain, sep="_")
  
  # centroid calculation
  newResName <- unique(df_coord$NewResName)
  df_centroidCoord <- data.frame()
  for(i in 1:length(newResName)){
  res_aus <- newResName[i]
  df_coord_aus <- df_coord[df_coord$NewResName %in% res_aus, ]
  coord_aus <- apply(df_coord_aus[,c("x","y","z")],2,mean)
  df_centroidCoord <- as.matrix(rbind(df_centroidCoord,coord_aus))
  }
  
  df_centroidCoord <- apply(df_centroidCoord,2,as.numeric)
  df_centroidCoord <- as.data.frame(df_centroidCoord)
  rownames(df_centroidCoord) <- newResName
  # contacts matrix definition
  DistMat <- as.matrix(dist(df_centroidCoord))
  vet_aa_inter <- c()
  for(i in 1:nrow(DistMat)){
  rownames_aus <- rownames(DistMat)[i]
  aa_aus <- unlist(strsplit(rownames_aus,"_"))[2]
  aa_int_aus <- names(DistMat[i,][DistMat[i,] <= cutoff & DistMat[i,]!=0])
  aa_int_aus_aus <-as.character(do.call(rbind,strsplit(aa_int_aus,"_"))[,2])
  vet_aa_inter <- c(vet_aa_inter, paste(aa_aus,aa_int_aus_aus, sep="-"))
  }
  summary_conct <- table(vet_aa_inter)
  summary_conct_prob <- summary_conct/sum(summary_conct)
  
  head(summary_conct)
  head(summary_conct_prob)
}

app2 <- function() {
  
  df_aa_contact <- pdb_aus$atom %>% 
    # filter only aminoacids
    filter(resid %in% aa.table$aa3) %>% 
    
    # add NewResName column
    mutate(NewResName = paste(resno, resid, chain, sep = "_")) %>% 
    
    # group by NewResName
    group_by(NewResName) %>% 
    
    # for each group defined below apply mean function on x y and z column: define centroids
    summarise(cx = mean(x), cy = mean(y), cz = mean(z)) %>% 
    
    # create all pair-wise of centroids
    full_join(x = ., y = ., by = character(), suffix = c("", "_2")) %>%
    
    # remove pair-wise same centroids
    filter(NewResName != NewResName_2) %>%
    
    # add new column distance. Now we have NewResName, cx, cy, cz, NewResName_2, cx_2, cy_2, cz_2, distance
    mutate(distance = sqrt((cx - cx_2)^2 + (cy - cy_2)^2 + (cz - cz_2)^2)) %>%
    
    # get only NewResName, NewResName_2, distance columns
    select(NewResName, NewResName_2, distance) %>%
    
    # get new dataframe wit pair_aa column (es ALA-ALA, ALA-ARG) and contact column based on cutoff
    summarise(
      pair_aa = paste(substr(NewResName, nchar(NewResName) - 4, nchar(NewResName) - 2), 
                      substr(NewResName_2, nchar(NewResName_2) - 4, nchar(NewResName_2) - 2), 
                      sep = "-"), 
      contact = if_else(distance < cutoff, 1, 0)
    ) %>%
    
    # group by pair_aa
    group_by(pair_aa) %>%
    
    # get new dataframe with pair_aa and contacts count for each pair
    summarise(count = sum(contact)) %>%
    
    # add frequence
    mutate(freq = count/sum(count))
  }
```

```{r, message=FALSE, warning=FALSE}
bm <- bench::mark(app1 = app1(), app2 = app2(), check = FALSE)
```

```{r}
bm %>% 
  select(c("expression", "min", "median", "itr/sec", "mem_alloc", "total_time"))
```

A causa di un bug non vediamo i nomi delle funzioni, ma il primo approccio risulta essere un po' più rapido del secondo. Tuttavia la memoria allocata è ben oltre il doppio. Inoltre, nel secondo approccio la maggior parte del tempo viene utilizzata per creare la colonna `pair_aa`... vuol dire che molto probabilmente non sono bravo a trattare le stringhe con `tidyverse`.

Ad ogni modo i pacchetti dell'universo `tidyverse` nascono per facilitare la scrittura e la comprensione del codice, non per la sua ottimizzazione. Questo vuol dire che buone pratiche di programmazione in `R-base` eguagliano o addirittura superano le prestazioni di `tidyverse`; tuttavia in `R-base` le buone pratiche bisogna conoscerle, mentre `tidyverse` per come è strutturato ti indirizza automaticamente verso le sue buone pratiche.

Nota finale: per prestazioni ottimali esistono altri pacchetti, di cui il più famoso e probabilmente il migliore è `data.table`. Forse `data.table` e `ggplot2` sono i migliori pacchetti in assoluto dell'universo `R`.